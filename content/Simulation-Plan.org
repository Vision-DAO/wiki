#+title: Vision Simulation Plan
#+author: Lawrence Qupty
#+date: <2022-08-03 Wed>

* Goals

Our goals in simulating Vision's tokenomics include understanding Vision's potential utility given our current road-map, which of Vision's features produce the best utility, and Vision's revenue streams.

We will collect data on the following:

- Overall utility
- Token distribution
- Deflation
- User growth

** Overall utility

*Overall utility*, in an abstract sense, is how much Vision users gain and lose.

To understand overall utility, we will be collecting market efficiency data on various file storage systems, as an effective file storage system is crucial for a decentralized service like Vision. We will also be trying to understand how Vision is able to handle various levels of voter fraud and the abilities of the Enforcer-jury model.

Specific data points may include:

- Deadweight loss (in the storage pricing market) due to staking
- Deadweight loss when there are no security measures
- Slashing rate
- Enforcer-jury model false positive rate
- Enforcer-jury false negative rate
  
** Token distribution

*Token distribution* is a measure concerned with where the Vision token, ~VIS~ ends up. Understanding token distribution allows us to answer questions like "Do people want to buy ~VIS~?" and "Who has control over Vision?"

Specific data points may include:

- A statistically random user's chance to buy ~VIS~
- Average user's volume of ~VIS~
- Distribution of ~VIS~ among all users
  
** Deflation

*Deflation* reflects how much ~VIS~ gets burned. Our goal is to understand which tokenomic policies lead to the most advantageous amount of deflation for maximum user utility.

Specific data points may include:

- Volume of ~VIS~ burned
- Which user actions lead to ~VIS~ being burned
- Market changes due to the value of ~VIS~ changing.
  
** User growth

*User growth* tells us how much utility is needed to attract or deter users from Vision. The data being collected under this category will be compared to metrics from the other categories, such as the file storage information from [[Overall utility]]. 

Specific data points may include:

- Chance a user is going to be discouraged or encouraged to use vision given the deadweight loss in the storage pricing market
- Chance a user is going to be discouraged or encouraged to use vision given the value of ~VIS~
- Chance a user is going to be discouraged or encouraged to use vision given how centralized/decentralized the distribution of ~VIS~ is.
  
* Methods

The methods used to simulate Vision's tokenomics will use simulation methods such as Monte Carlo via radCad (a sort of successor to cadCad) combined with statistical analysis methods such as Bayesian inference.

We will have different simulation layers for each data category listed in the [[Goals]] section. These layers can be combined to strengthen predictive power. This makes it possible to extend the simulation as more data gets provided from live Vision tests (such as Testnet) or elsewhere.
